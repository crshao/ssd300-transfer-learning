{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "celtic-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from misc_utils.tensor_sampling_utils import sample_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exciting-voltage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trained_weights/VGG_coco_SSD_300x300_iter_400000_subsampled_5_classes.h5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Set the path for the source weights file you want to load.\n",
    "\n",
    "weights_source_path = 'trained_weights/VGG_coco_SSD_300x300_iter_400000.h5'\n",
    "\n",
    "# TODO: Set the path and name for the destination weights file\n",
    "#       that you want to create.\n",
    "\n",
    "weights_destination_path = 'trained_weights/VGG_coco_SSD_300x300_iter_400000_subsampled_5_classes.h5'\n",
    "\n",
    "# Make a copy of the weights file.\n",
    "shutil.copy(weights_source_path, weights_destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suburban-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both the source weights file and the copy we made.\n",
    "# We will load the original weights file in read-only mode so that we can't mess up anything.\n",
    "weights_source_file = h5py.File(weights_source_path, 'r')\n",
    "weights_destination_file = h5py.File(weights_destination_path, 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recorded-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_names = ['conv4_3_norm_mbox_conf',\n",
    "                    'fc7_mbox_conf',\n",
    "                    'conv6_2_mbox_conf',\n",
    "                    'conv7_2_mbox_conf',\n",
    "                    'conv8_2_mbox_conf',\n",
    "                    'conv9_2_mbox_conf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "animated-delivery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the 'conv4_3_norm_mbox_conf' weights:\n",
      "\n",
      "kernel:\t (3, 3, 512, 324)\n",
      "bias:\t (324,)\n"
     ]
    }
   ],
   "source": [
    "conv4_3_norm_mbox_conf_kernel = weights_source_file[classifier_names[0]][classifier_names[0]]['kernel:0']\n",
    "conv4_3_norm_mbox_conf_bias = weights_source_file[classifier_names[0]][classifier_names[0]]['bias:0']\n",
    "\n",
    "print(\"Shape of the '{}' weights:\".format(classifier_names[0]))\n",
    "print()\n",
    "print(\"kernel:\\t\", conv4_3_norm_mbox_conf_kernel.shape)\n",
    "print(\"bias:\\t\", conv4_3_norm_mbox_conf_bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "small-generator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 52, 53, 55, 56, 57, 81, 133, 134, 136, 137, 138, 162, 214, 215, 217, 218, 219, 243, 295, 296, 298, 299, 300]\n"
     ]
    }
   ],
   "source": [
    "n_classes_source = 81\n",
    "# classes_of_interest = [0, 3, 8, 1, 2, 10, 4, 6, 12] # diganti jadi yang buah dan sayur\n",
    "classes_of_interest = [0, 52, 53, 55, 56, 57] # banana, apple, orange, broccoli, carrot\n",
    "\n",
    "subsampling_indices = []\n",
    "for i in range(int(324/n_classes_source)):\n",
    "    indices = np.array(classes_of_interest) + i * n_classes_source\n",
    "    subsampling_indices.append(indices)\n",
    "subsampling_indices = list(np.concatenate(subsampling_indices))\n",
    "\n",
    "print(subsampling_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "arranged-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set the number of classes in the source weights file. Note that this number must include\n",
    "#       the background class, so for MS COCO's 80 classes, this must be 80 + 1 = 81.\n",
    "n_classes_source = 81\n",
    "# TODO: Set the indices of the classes that you want to pick for the sub-sampled weight tensors.\n",
    "#       In case you would like to just randomly sample a certain number of classes, you can just set\n",
    "#       `classes_of_interest` to an integer instead of the list below. Either way, don't forget to\n",
    "#       include the background class. That is, if you set an integer, and you want `n` positive classes,\n",
    "#       then you must set `classes_of_interest = n + 1`.\n",
    "# classes_of_interest = [0, 3, 8, 1, 2, 10, 4, 6, 12]\n",
    "# classes_of_interest = 9 # Uncomment this in case you want to just randomly sub-sample the last axis instead of providing a list of indices.\n",
    "classes_of_interest = [0, 52, 53, 55, 56, 57] # banana, apple, orange, broccoli, carrot\n",
    "for name in classifier_names:\n",
    "    # Get the trained weights for this layer from the source HDF5 weights file.\n",
    "    kernel = weights_source_file[name][name]['kernel:0'][:]\n",
    "    bias = weights_source_file[name][name]['bias:0'][:]\n",
    "\n",
    "    # Get the shape of the kernel. We're interested in sub-sampling\n",
    "    # the last dimension, 'o'.\n",
    "    height, width, in_channels, out_channels = kernel.shape\n",
    "    \n",
    "    # Compute the indices of the elements we want to sub-sample.\n",
    "    # Keep in mind that each classification predictor layer predicts multiple\n",
    "    # bounding boxes for every spatial location, so we want to sub-sample\n",
    "    # the relevant classes for each of these boxes.\n",
    "    if isinstance(classes_of_interest, (list, tuple)):\n",
    "        subsampling_indices = []\n",
    "        for i in range(int(out_channels/n_classes_source)):\n",
    "            indices = np.array(classes_of_interest) + i * n_classes_source\n",
    "            subsampling_indices.append(indices)\n",
    "        subsampling_indices = list(np.concatenate(subsampling_indices))\n",
    "    elif isinstance(classes_of_interest, int):\n",
    "        subsampling_indices = int(classes_of_interest * (out_channels/n_classes_source))\n",
    "    else:\n",
    "        raise ValueError(\"`classes_of_interest` must be either an integer or a list/tuple.\")\n",
    "    \n",
    "    # Sub-sample the kernel and bias.\n",
    "    # The `sample_tensors()` function used below provides extensive\n",
    "    # documentation, so don't hesitate to read it if you want to know\n",
    "    # what exactly is going on here.\n",
    "    new_kernel, new_bias = sample_tensors(weights_list=[kernel, bias],\n",
    "                                          sampling_instructions=[height, width, in_channels, subsampling_indices],\n",
    "                                          axes=[[3]], # The one bias dimension corresponds to the last kernel dimension.\n",
    "                                          init=['gaussian', 'zeros'],\n",
    "                                          mean=0.0,\n",
    "                                          stddev=0.005)\n",
    "    \n",
    "    # Delete the old weights from the destination file.\n",
    "    del weights_destination_file[name][name]['kernel:0']\n",
    "    del weights_destination_file[name][name]['bias:0']\n",
    "    # Create new datasets for the sub-sampled weights.\n",
    "    weights_destination_file[name][name].create_dataset(name='kernel:0', data=new_kernel)\n",
    "    weights_destination_file[name][name].create_dataset(name='bias:0', data=new_bias)\n",
    "\n",
    "# Make sure all data is written to our output file before this sub-routine exits.\n",
    "weights_destination_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "civil-communication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the 'conv4_3_norm_mbox_conf' weights:\n",
      "\n",
      "kernel:\t (3, 3, 512, 24)\n",
      "bias:\t (24,)\n"
     ]
    }
   ],
   "source": [
    "conv4_3_norm_mbox_conf_kernel = weights_destination_file[classifier_names[0]][classifier_names[0]]['kernel:0']\n",
    "conv4_3_norm_mbox_conf_bias = weights_destination_file[classifier_names[0]][classifier_names[0]]['bias:0']\n",
    "\n",
    "print(\"Shape of the '{}' weights:\".format(classifier_names[0]))\n",
    "print()\n",
    "print(\"kernel:\\t\", conv4_3_norm_mbox_conf_kernel.shape)\n",
    "print(\"bias:\\t\", conv4_3_norm_mbox_conf_bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "empty-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "from models.keras_ssd300 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.object_detection_2d_patch_sampling_ops import RandomMaxCropFixedAR\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "expected-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 300 # Height of the input images\n",
    "img_width = 300 # Width of the input images\n",
    "img_channels = 3 # Number of color channels of the input images\n",
    "subtract_mean = [123, 117, 104] # The per-channel mean of the images in the dataset\n",
    "swap_channels = [2, 1, 0] # The color channel order in the original SSD is BGR, so we should set this to `True`, but weirdly the results are better without swapping.\n",
    "# TODO: Set the number of classes.\n",
    "n_classes = 8 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "scales = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05] # The anchor box scaling factors used in the original SSD300 for the MS COCO datasets.\n",
    "# scales = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05] # The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets.\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [8, 16, 32, 64, 100, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not you want to limit the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are scaled as in the original implementation\n",
    "normalize_coords = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "crude-finish",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.backend' has no attribute 'image_dim_ordering'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2f7a46d4adea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Clear previous models from memory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m model = ssd_300(image_size=(img_height, img_width, img_channels),\n\u001b[0m\u001b[0;32m      6\u001b[0m                 \u001b[0mn_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inference'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Project\\ssd_keras\\models\\keras_ssd300.py\u001b[0m in \u001b[0;36mssd_300\u001b[1;34m(image_size, n_classes, mode, l2_regularization, min_scale, max_scale, scales, aspect_ratios_global, aspect_ratios_per_layer, two_boxes_for_ar1, steps, offsets, clip_boxes, variances, coords, normalize_coords, subtract_mean, divide_by_stddev, swap_channels, confidence_thresh, iou_threshold, top_k, nms_max_output_size, return_predictor_sizes)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;31m# Feed conv4_3 into the L2 normalization layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mconv4_3_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL2Normalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'conv4_3_norm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv4_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;31m### Build the convolutional predictor layers on top of the base network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Project\\ssd_keras\\keras_layers\\keras_layer_L2Normalization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, gamma_init, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_dim_ordering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tf'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# FIXED from K.image_dim_ordering()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.backend' has no attribute 'image_dim_ordering'"
     ]
    }
   ],
   "source": [
    "# 1: Build the Keras model\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='inference',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=subtract_mean,\n",
    "                divide_by_stddev=None,\n",
    "                swap_channels=swap_channels,\n",
    "                confidence_thresh=0.5,\n",
    "                iou_threshold=0.45,\n",
    "                top_k=200,\n",
    "                nms_max_output_size=400,\n",
    "                return_predictor_sizes=False)\n",
    "\n",
    "print(\"Model built.\")\n",
    "\n",
    "# 2: Load the sub-sampled weights into the model.\n",
    "\n",
    "# Load the weights that we've just created via sub-sampling.\n",
    "weights_path = weights_destination_path\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "print(\"Weights file loaded:\", weights_path)\n",
    "\n",
    "# 3: Instantiate an Adam optimizer and the SSD loss function and compile the model.\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
